{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy and Pandas\n",
    "\n",
    "Numpy and Panda are two increadibly powerful Python libraries. They are used for most tasks connected with manipulating data. In this notebook I go into a lot of detail about what they can do. \n",
    "\n",
    "While you will need only basic understaqnding of Numpy and Panda for the rest of this course, you are very likely to encounter a lot of them if you get deeper into analysing data with Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### range and creating stings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list('ABCDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i*2 for i in [0,1,2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in range(0, 50, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f\"{i} to {i+9}\" \n",
    " for i in range(0, 50, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use the \" {} \".format(variable)\n",
    "[\"{} to {}\".format(i,i + 9)\n",
    " for i in range(0, 50, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and it also supports variable names:\n",
    "[\"{start} to {end}\".format(start = i, end = i + 9)\n",
    " for i in range(0, 50, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which is most useful when you want to repeat the same value or calculation:\n",
    "\n",
    "[\"formats of range from {start} to {end}: {start}-{end}, {start} to {end}, {start}..{end}\".format(start=i, end=i + 9)\n",
    " for i in range(0, 50, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formating stirngs with .format() is especially useful when you split responsibilities amongs your team:\n",
    "\n",
    "- one person writes the message (eg. copywriter),\n",
    "- one person writes tghe logic (business analyst)\n",
    "- yet another person will combine them together (programmer)\n",
    "\n",
    "like in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_message = \"Dear {name}. Your gift card is expiring, you have £{money_left} and {days_left} days to use it\"\n",
    "\n",
    "data_from_api = {'name':\"Clara\", 'money_left': 13.35, 'days_left': 3}\n",
    "\n",
    "print(customer_message.format(**data_from_api))\n",
    "\n",
    "# note, the ** will explode your Dict into individual variables. It is explained below in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New (but very rare): Explode operator **\n",
    "\n",
    "Explode operator is a rare, but often very useful way to 'explode' a dictionary into a number of variables.\n",
    "\n",
    "You can imagine that when you explode a dictionary:\n",
    "`\n",
    "data_from_api = {'name':\"Clara\", 'money_left': 13.35, 'days_left': 3}\n",
    "`\n",
    "\n",
    "Like this:\n",
    "\n",
    "`\n",
    "**data_from_api\n",
    "`\n",
    "\n",
    "It is interpreted as:\n",
    "\n",
    "`\n",
    "name = \"Clara\"\n",
    "money_left =  13.35\n",
    "days_left = 3\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can use ** explode operator to feed dictionaries  .format() string formatting or functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_api = {'name':\"Clara\", 'money_left': 13.35, 'days_left': 3}\n",
    "\n",
    "customer_message = \"Dear {name}. Your gift card is expiring, you have £{money_left} and {days_left} days to use it\"\n",
    "print(customer_message.format(**data_from_api))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_report(name, money_left, days_left):\n",
    "    return f\"{name} has {days_left} days left to spend £{money_left}\"\n",
    "\n",
    "data_from_api = {'name':\"Clara\", 'money_left': 13.35, 'days_left': 3}\n",
    "\n",
    "print( customer_report(**data_from_api)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is most useful when you do not want to write everything by yourself, but also when the data is coming from ourseide (api, key) and you need flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional arguments:\n",
    "range(9)\n",
    "range(1,9)\n",
    "range(1,9,3)\n",
    "\n",
    "# named arguments:\n",
    "def divide(first, second):\n",
    "    return first / second\n",
    "\n",
    "print( divide(2, 8)  )\n",
    "print( divide(first = 2, second = 8)  )\n",
    "print( divide(second = 8, first = 2)  ) # order does not matter anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_percent_string(number, decimal_places = 0, symbol = \"%\"):\n",
    "    number *= 100\n",
    "    return \"{num:.{dec}f}{sym}\".format(num = number, sym = symbol, dec = decimal_places)\n",
    "\n",
    "print( as_percent_string(2/3) )\n",
    "print( as_percent_string(2/3, decimal_places = 2) )\n",
    "print( as_percent_string(2/3, symbol = \" percent\") )\n",
    "print( as_percent_string(2/3, decimal_places = 1, symbol = \" percent\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print has an optional argument 'end' which decides what character to put at the end.\n",
    "# by default is equal to '/n' (meaning new line), but you can change it to anything\n",
    "\n",
    "print(\"2\")\n",
    "print(\"4\")\n",
    "print(\"7\")\n",
    "print()\n",
    "\n",
    "print(\"2\",end=\"\")\n",
    "print(\"4\",end=\"\")\n",
    "print(\"7\",end=\"\")\n",
    "print()\n",
    "\n",
    "print(\"2\",end=\"\\t\")\n",
    "print(\"4\",end=\"\\t\")\n",
    "print(\"7\",end=\"\\t\")\n",
    "print()\n",
    "\n",
    "separator = \"****\"\n",
    "print(\"2\",end=separator)\n",
    "print(\"4\",end=separator)\n",
    "print(\"7\",end=separator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Numpy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are Numpy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy and Pandas are two very useful libraries for dealing with data in Python. They work so closely together that often you might not know where one starts and the other ends. One basic distinction is:\n",
    "\n",
    "- **Numpy** is for basic numerical operations (mean, range, etc), especially on multidimentional arrays (sort of like Lists of Lists of Lists...)\n",
    "\n",
    "- **Pandas** is for advance data operations arranging, cleaning up, analysis, but also can be used for data input and a few other commond tasks in data analysis.\n",
    "\n",
    "Let's look at some features that become easier with Numpy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before we use them, as with all other libraries, we will need to import them. Becuase we will use their name frequently, it is frequent to import them and give them both shorter names:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "so that you can use theis short name like this:\n",
    "\n",
    "```\n",
    "np.zeros(10, dtype='int')\n",
    "```\n",
    "\n",
    "rather than having to type every time\n",
    "\n",
    "```\n",
    "numpy.zeros(10, dtype='int')\n",
    "```\n",
    "\n",
    "Note: it does not save you a lot of typing, but is done a lot. You can choose to not use 'as short_name' syntax, but be aware that other people might. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays - new data type, like more powerful Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy introduces a new data type called **Array**. It is basically like a List, but has s number of new very powerful methods and syntax that make data operations easier and faster.\n",
    "\n",
    "Teoretically you could do everything that we do with Arrays by just using good old Lists, but it would take more time and be less compatible with other libraries.\n",
    "\n",
    "To create an Array, you can cast a list into ```np.array( your_list )``` just like you could cast your list into a set ```set(your_list)``` or a decimal number into an whole number ```int(3.14)```\n",
    "\n",
    "Notice the ```np.array``` at the begining - it means that you are using the ```array class``` from the ```np``` library. ```np``` is a short name for ```numpy``` (which you yourself gave it in ```import numpy as np```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "my_list = [3, 7, 5, 5]\n",
    "print(my_list)\n",
    "\n",
    "# you can create an array by feeding in a List, as a variable or directly:\n",
    "\n",
    "my_array = np.array(my_list)\n",
    "print(my_array)\n",
    "\n",
    "my_array2 = np.array([3, 0, 5, 0])\n",
    "print(my_array2)\n",
    "\n",
    "# notice it is printed a bit differently than a list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays are often used in situations where there are many dimensions. So a grid of \n",
    "\n",
    "`\n",
    "3755\n",
    "0159\n",
    "3050\n",
    "`\n",
    "\n",
    "Can be represented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([\n",
    "                    [3, 7, 5, 5],\n",
    "                    [0, 1, 5, 9],\n",
    "                    [3, 0, 5, 0]\n",
    "                   ])\n",
    "\n",
    "\n",
    "print(scores)\n",
    "\n",
    "# let's print what type of a thing it is:\n",
    "print(type(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: Lists with many dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time yoru data has many dimentions. \n",
    "\n",
    "- variable has **zero dimentions** - you do not need any more index/address to know what's in it\n",
    "- list/array has **one dimention** - index is the way to address individual items in a list\n",
    "- list of lists has **two dimentions** - index of the top list, and then an index of the inned list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we already sometimes used multi-dimentional lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a two-dimentional list:\n",
    "list_of_lists = [[3,4,5,6,7], [30,40,50,60,70]] \n",
    "\n",
    "# print the big list\n",
    "print(list_of_lists) \n",
    "\n",
    "# print first sub-list\n",
    "print(list_of_lists[0]) \n",
    "\n",
    " # print first number in first sub-list\n",
    "print(list_of_lists[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get from the second array it's fourth element (which should be 60), you would use\n",
    "print(list_of_lists[1][3])\n",
    "\n",
    "# to get from the first array it's last element (which should be 7), you would use\n",
    "print(list_of_lists[0][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Arrays with many dimensions and new addressing style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numpy and pandas we will most of the time deal with multidimentional data - with 2,3 or even more dimentions. The dimentions will have a meaning, just like in Excel rows and columns have meanings. We will talk about it soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEW ADDRESSING STYLE - my_array[3,6]**\n",
    "\n",
    "- In Lists, to addressed a value by ```my_list[first_dimention][second_dimention]``` like ```stops[3][7]```\n",
    "- In Arrays, we can also use        ```my_list[first_dimention, second_dimention]``` like ```stops[3, 7]```\n",
    "\n",
    "From now on when you are getting numbers from arrays, you can pass in index of each next dimention separated by comas.\n",
    "\n",
    "note: in Arrays you can still use the old format ```stops[3][7]```, but the new one ```stops[3, 7]``` is more common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some multi-dimentional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([ [3, 7, 5, 5],\n",
    "                    [0, 1, 5, 9],\n",
    "                    [4, 0, 5, 0]\n",
    "                   ])\n",
    "\n",
    "# in the new indexing style, indexes for each next dimension are separated with a coma\n",
    "# your_array[first_dimension, second_dimension, third_dimension, ....]\n",
    "\n",
    "print(scores[0,0])\n",
    "print(scores[0,1])\n",
    "print(scores[2,0])\n",
    "print(scores[2,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in Lists you can use the index not only to GET the value, but also to CHANGE the value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([ [3, 7, 5, 5],\n",
    "                    [0, 1, 5, 9],\n",
    "                    [4, 0, 5, 8]\n",
    "                   ])\n",
    "\n",
    "# let's change some items\n",
    "\n",
    "scores[0,0] = 10\n",
    "scores[0,1] = 20\n",
    "scores[1,3] += 30\n",
    "scores[-1,-1] += 40\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can request some information about your arrays, just ike you could request a len() from a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can request some info about a multi-level Array:\n",
    "scores = np.array([ [3, 7, 5, 5],\n",
    "                    [0, 1, 5, 9],\n",
    "                    [4, 0, 5, 0]\n",
    "                   ])\n",
    "\n",
    "print(\"dimentions\", scores.ndim)\n",
    "print(\"shape\", scores.shape)\n",
    "print(\"size \", scores.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Arrays full of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the default value and type of your new empty array:\n",
    "\n",
    "- full of zeros with .zeros()\n",
    "- full of ones with .ones()\n",
    "- full of some other value with .full(some_value)\n",
    "- full of random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros( 4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, created values are floats (numbers with decimal places), but you can specify data type with 'dtype':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(5, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(5, dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create multi-dimentional arrays with sizes of all dimentions in a tupple:\n",
    "\n",
    "(3) - array of 3 elements\n",
    "(3,5) - 3 sets of 5 elements\n",
    "(3,5,10) - 3 sets of 5 sets of 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3,5), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3,5,10), dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify values other than zero with `.ones( dimensions )` or with `.full(dimensions, value)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((2,5), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.full((2,5), 3.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create values\n",
    "\n",
    "- from a range with `arange(start, top, jump)`\n",
    "- with even split between two values `linspace(start, end, slices)`\n",
    "- indentity matrix with `eye(size)`\n",
    "- full of random data with `np.random.randint(max_value, size=size_tupple)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(5, 25, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, 1, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random numbers\n",
    "\n",
    "print(np.random.randint(10, size=6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is really computer-sciency, but you might enjoy it: \n",
    "\n",
    "### Randomness in computers is pseudo-random (not really 'random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be a bit Computer-Science-Heavy, but it's ok if you only understand some of it.\n",
    "\n",
    "Mind you, this is a **huge simplification**, but basically for this course we will not worry about seeding our randomness, but be aware that your random numbers might repeat, and the seed is to blame.\n",
    "\n",
    "In computers getting actual real randomness is very diffeicult, because everything requires a cause and effect. \n",
    "\n",
    "One of the ways to get a computer to create 'random' numbers is to pick some 'noise' and interpret it as numbers. For example you could pick some unocupied place in memory (sort of like a rubbish pile, full of variable leftovers of old files) and start reading it as if these were purposeful numbers. \n",
    "\n",
    "These data would make no sense, and not follow any obvious pattern, so would be in some way 'random'. But also they would be guessable (with a lot of effort) and if by any chance you were to start reading your rubbish data at the EXACT SAME POINT, you would end up with the EXACT SAME RANDOM NUMBERS... which would make them not a very useful randomness. Another problem could be that if you somehow dug up a very repetitive file (eg. eg an .mp3 music file with a lot of silence) you might end up with a lot of repeated numbers and some numbers missing completely (eg. if mp3 files use 0 to describe silence you would get disproportionately many 0 in your randomness).\n",
    "\n",
    "On some level you could think of that first place from which you started reading your 'noise' as a SEED from which the random numbers will grow. One way to avoid the 'repetitive noise' like in the above example of mp3 file is what Python does: it uses some SEED as the address of  RANDOM_VALUE_1, and then instead of reading the next piece of noise it finde, it uses the value of RANDOM_VALUE_1 as an address in noise to find RANDOM_VALUE_2. And then if uses 'ranom' RANDOM_VALUE_2 as the address to find RANDOM_VALUE_3 and so on. \n",
    "\n",
    "It's a sif you had some 'noise' ```[3,6,5,8,7,3,1,9]``` and wanted random values with seed ```2```. \n",
    "\n",
    "- first random number would be value on the address/index of ```2``` ----> value ```5```\n",
    "- next random number would be value on the address/index of ```5``` ----> value ```3```\n",
    "- first random number would be value on the address/index of ```3``` ----> value ```8```\n",
    "- etc.\n",
    "\n",
    "The basic problem is: **IF YOU START AT THE SAME SEED, YOU WILL END UP WITH THE SAME SEQUENCE OF RANDOM NUMBERS**\n",
    "\n",
    "That's why best seeds are the ones which change all the time. A good example is time in miliseconds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a few random numbers in python:\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))\n",
    "\n",
    "#every time you run this cell, your random numbers will be differnt. Try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but if you specify a seed, your random numbers will be the same every time you run this cell!\n",
    "\n",
    "np.random.seed(0) # plant the seed 0 - this could be any number\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))\n",
    "\n",
    "print()\n",
    "\n",
    "np.random.seed(0)\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))\n",
    "\n",
    "# WHY WOULD ANYONE DO THIS? Well... it's great for debugging! You could write tests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best thing to do if you are concerned for the 'real randomness' of your numbers is\n",
    "# to use time now in miliseconds as the seed. Time changes constantly and never repeats, so it's ideal.\n",
    "\n",
    "import time\n",
    "time_now = int(time.time()) # time in seconds since 1 Jan 1970\n",
    "print(time_now)\n",
    "np.random.seed(time_now) # plant the seed time_now this number changes every second\n",
    "\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed this is done so much, that numpy has a built-in shortcut for it: just use ```np.random.seed()``` with no argument and you will seed current time. This way you never need to worry about randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed() # this will use current exact time (probably in microseconds) as a seed\n",
    "print(np.random.randint(10, size=6))\n",
    "print(np.random.randint(10, size=6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often should you do it? It does not really matter, but you could do it before generating some important random numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Arrays full of Random values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE DIMENTION - with size 6\n",
    "array1 = np.random.randint(100, size=6)\n",
    "print(array1)\n",
    "print(array1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO DIMENTIONS - with size 4 for first and 5 for the second\n",
    "# these could be scores for four courses, each with 5 students\n",
    "array2 = np.random.randint(100, size=(4,5))\n",
    "print(array2)\n",
    "print()\n",
    "\n",
    "print(array2[3])\n",
    "print(array2[3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THREE DIMENTIONS - with size 2 for first and 4 for the second and 5 for third\n",
    "# these could be scores for two departments, each with four courses, each with 5 students\n",
    "\n",
    "array3 = np.random.randint(100, size=(3,4,5))\n",
    "print(\"whole array:\")\n",
    "print(array3)\n",
    "print()\n",
    "\n",
    "print(\"second item:\")\n",
    "print(array3[1])\n",
    "print()\n",
    "\n",
    "print(\"second item's fourth item:\")\n",
    "print(array3[1,3])\n",
    "print()\n",
    "\n",
    "print(\"second item's fourth item's fifth item:\")\n",
    "print(array3[1,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing/Subsets of Arrays - just like in Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_array[start:ceiling] if someting is not specified, it takes the extreme value\n",
    "# my_array[:5] means from begining till 5th, my_array[5:] means from 6th till end\n",
    "\n",
    "digits = np.arange(9)\n",
    "print(digits)\n",
    "print(digits[:5])\n",
    "print(digits[5:])\n",
    "print(digits[5:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the new index-range syntax:    my_array[ start_index : ceiling_index : jump]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also new syntax (that also works for Lists, but you might have never seen it before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_array[ start_index : ceiling_index : jump]\n",
    "\n",
    "digits = np.arange(10,20)\n",
    "print(digits)\n",
    "print()\n",
    "print(digits[2:7:2]) # from index 2, till index 7, jumping every 2\n",
    "print(digits[:7:2]) # from beginning, till index 7, jumping every 2\n",
    "print(digits[2::2]) # from index 2, till end, jumping every 2\n",
    "print(digits[::2]) # all, jumping every 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and to make it more interesting: when jump is -2, what will happen?\n",
    "# the array gets reversed (draw it on a piece of paper to understand it better)\n",
    "print(digits[::-1]) # all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping - changing the dimensions of an Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.arange(12) ) \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.arange(12).reshape((2,6)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.arange(12).reshape((4,3)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( np.arange(12).reshape((3,2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but what would this do?\n",
    "print( np.arange(12).reshape((4,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating/Flattening Arrays and Lists - removing one dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```np.concatenate()``` takes one argument - a List/Array and will combine all of it's items into an Array. \n",
    "\n",
    "concatenate will remove one dimension:\n",
    " ```[[1,2,3], [4,5,6]]  ---> [1,2,3,4,5,6]```\n",
    " \n",
    "You can think of concatenate as a **JOIN THE ARRAYS IN THIS ARRAY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array([10,20,30])\n",
    "array2 = np.array([40,50,60])\n",
    "print( np.concatenate([array1, array2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [70, 80,90]\n",
    "list2 = [1, 2, 3]\n",
    "\n",
    "print( np.concatenate([list1, list2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can concatenate lists and arrays together. They really are very simmilar\n",
    "\n",
    "array1 = np.array([10,20,30])\n",
    "array2 = np.array([40,50,60])\n",
    "list1 = [70, 80,90]\n",
    "print( np.concatenate([array1, array2, list1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation respects dimentions, it will flatten only the top dimension\n",
    "two_dimention_array1 = np.array([ [1,2,3],    [4,5,6] ])\n",
    "two_dimention_array2 = np.array([ [10,20,30], [40,50,60] ])\n",
    "\n",
    "print(two_dimention_array1)\n",
    "print(two_dimention_array2)\n",
    "\n",
    "print()\n",
    "print( np.concatenate([two_dimention_array1,two_dimention_array2]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this starts being spaghetti code, but you could flatten something twice and remove two dimensions\n",
    "\n",
    "print( np.concatenate( np.concatenate( [two_dimention_array1,two_dimention_array2] ) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate has an extra argument axis ```np.concatenate([arr1,arr2],axis=1)``` which by default is 0\n",
    "\n",
    "- axis=0 (the default) - flatten horisontally - remove one dimension from all items in list\n",
    "- axis=1 - flatter vertically - combine all first items, then all second items, all third... etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dimention_array1 = np.array([ [1,2,3], [4,5,6] ])\n",
    "two_dimention_array2 = np.array([ [10,20,30], [40,50,60] ])\n",
    "\n",
    "print( np.concatenate([two_dimention_array1,two_dimention_array2], axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dimention_array1 = np.array([ [1,2,3], [4,5,6] ])\n",
    "two_dimention_array2 = np.array([ [10,20,30], [40,50,60] ])\n",
    "\n",
    "print( np.concatenate([two_dimention_array1,two_dimention_array2], axis=1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horisontal and Vertical Stack -  add Arrays to each other without losing dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array([-7,-8,-9])\n",
    "my_array_2d = np.array([ [1,2,3], [4,5,6] ])\n",
    "\n",
    "print(np.vstack([my_array, my_array_2d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array_2d_1 = np.array([[-1,-2],[-3, -4]])\n",
    "my_array_2d_2 = np.array([ [1,2,3], [4,5,6] ])\n",
    "\n",
    "print(np.hstack([my_array_2d_1, my_array_2d_2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split - split one Array into many Arrays using predefined indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = np.arange(1,10)\n",
    "print(digits)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_sub_arrays = np.split(digits,[3,6])\n",
    "print(three_sub_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have not seen this syntaxt yet, it's typical to advanced Python. \n",
    "# You can specify many variables in one line, but assigning a List to them\n",
    "a,b,c = [10,20,30]\n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the split can be used as follows:\n",
    "start, middle, end = np.split(digits,[3,6])\n",
    "print(start, middle, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you could achieve the same effect with many lines of code with range()\n",
    "# but that requires much more thinking and opportunities for bugs\n",
    "\n",
    "first = np.arange(1,4)\n",
    "second = np.arange(4,7)\n",
    "third = np.arange(7,10)\n",
    "print(first, second, third)\n",
    "\n",
    "# but why do something the hard way if there is a proper syntax for it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all together:\n",
    "\n",
    "digits = np.arange(0,20).reshape(5,4)\n",
    "print(digits)\n",
    "print()\n",
    "\n",
    "first, second, third = np.vsplit(digits,[2,3])\n",
    "print(first)\n",
    "print(second)\n",
    "print(third)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Pandas we will work more and more with real data. Many concepts will be familiar to you from Excel and other data-briwsing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame - a more powerful Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keys are column names\n",
    "- Values as Arrays/Lists with rows\n",
    "\n",
    "**DataFrame is to a Dict what Array was to a List**\n",
    "\n",
    "To create a DataFrame we put a Dict it its constructor. But remember that values need to be lists. Like this:\n",
    "\n",
    "```\n",
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz'], 'year': [1,1,2] })\n",
    "   ```\n",
    "   \n",
    "You can access DataFrame columns, like you would variables in an object\n",
    "\n",
    "```data.names``` or ```data['names']```\n",
    "\n",
    "you can get "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Subsets - get some Rows, get some Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we use them, we'll need to import Pandas once per notebook (it's not a problem if you import them a few times)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz'], 'year': [1,1,2] })\n",
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row subset work like with Arrays, above  dataframe[start: ceiling : jump ]\n",
    "print(data[1:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0:3:2])  # jump every 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a column\n",
    "print(data.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get individual items\n",
    "print(data.names[0])\n",
    "print(data.names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get individual items\n",
    "print(data.names[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new column to dataframe works just like adding a new key-value pair to a Dict\n",
    "\n",
    "data = pd.DataFrame({'names': ['Judy', 'Kim', 'Shaz'], 'year': [1,1,2] })\n",
    "data['department'] = ['business', 'math', 'business']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ```print()``` DataFrames and they will be arranged into a nice readable format, but you can also return them (make them the last item in your Notetebook cell) and they will be displayed in an even nicer format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'name' : ['Judy', 'Kim', 'Shaz', 'Natt', 'Gill'],\n",
    "                   'surname' : ['OBrien', 'Gunn', 'Dice', 'Johnes', 'Roy'],\n",
    "                   'semester' : [1,1,2,2,1],\n",
    "                   'score' : [3.7, 4.6, 8.2, 2.6, 3.7],\n",
    "                   'penalty' : [0.5, 0.0, 0.8, 0.0, 0.2]})\n",
    "\n",
    "# when printed in a cell it is simple\n",
    "print(\"printed version:\\n\", data)\n",
    "\n",
    "# when returned from a cell it is prettier\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can produce some simple statistics about numeric values in your data with describe() \n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get information abotu data types and sizes of data you can use info()\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sort_values takes a number of arguments:\n",
    "\n",
    "- ```by``` is a List of columns to sort the data by, in order. First items are sorted by first item in this list. If there is a tie, they are sorted by second item, etc.\n",
    "- ```inplace``` is a True/False value indicating whether the new value should be returned, or put back into the sorted dataframe. Use ```inplace=False``` If you want to print or output data, and use ```inplace=True``` if you want to change your actual data.\n",
    "- ```ascending``` takes either True/False value, or a list of True/False values (if sorting by many columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['semester','score'],ascending=True,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['semester','score'],ascending=[False, True],inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['score', 'penalty'],ascending=True,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['surname'],ascending=True,inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Duplicates with drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we learn how to remove duplicates, I will show you how to create some:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplying items combines them. Multiplying item by x is like adding it to itself x many times\n",
    "\n",
    "print(3 * 3)\n",
    "print('3' * 3)\n",
    "print([3] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be combined with actual adding\n",
    "print([1,1,1] + [2,2])\n",
    "print(['sales'] * 3 + ['marketting']*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some duplicates and remove them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4, 'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "offices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices.sort_values(by='floor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices.drop_duplicates(subset='department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices.drop_duplicates(subset='floor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping columns values with .map( ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously when we used map, it was a python method, into which we had to pass the list we wanted to map.\n",
    "\n",
    "```map(mapping_function, my_list)```\n",
    "\n",
    "That was a bit confusing, becuase methods usually are called on objects. It would make more sense for map to work like this:\n",
    "\n",
    "```my_list.map(mapping_function)```\n",
    "\n",
    "And Pandas give us the ability to do exacltyu that! Well... on Arrays, not Lists, but that's close enough.\n",
    "\n",
    "```my_data_frame.map(mapping_function)```\n",
    "\n",
    "**YOU CAN CHAIN .MAP( )** which makes certain tasks much simpler, like in \n",
    "\n",
    "```name.map(mapping_function_1).map(mapping_function_2)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'fruits' : [\"banana\",  \"kiwi\", \"apple\"]})\n",
    "\n",
    "data['lengths'] = data['fruits'].map(len)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4, 'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "offices['floor'] = offices['floor'].map(lambda floor: f\"Floor {floor}\")\n",
    "offices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offices = pd.DataFrame({'department':['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4, 'floor':[1,2,3,1,2,3,3,3,1,1,1,2]})\n",
    "\n",
    "floor_names = {1: 'Ground Floor', 2: 'Main Floor', 3: \"Roof Floor\"}\n",
    "\n",
    "offices['floor'] = offices['floor'].map(lambda floor: floor_names[floor] )\n",
    "offices\n",
    "print(['sales'] * 3 + ['marketing']*5 + ['r&d'] * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up data with .map( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an **example of chaining** ```.map( )``` to clean up data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "offices = pd.DataFrame({\n",
    "    'department': ['-Sales-', 'sales  ', '-SALES-', 'marketing', 'MARKETING', '-marketing-', 'Marketing', '  marketing', '-R&D-', ' r&d', 'r&d  ', 'r&d'],\n",
    "    'floor':[1,2,3,1,2,3,3,3,1,1,1,2]\n",
    "})\n",
    "department_codes = {'sales': \"SAL\", 'marketing': \"MAR\", 'r&d': \"RND\" }\n",
    "\n",
    "# lambdas\n",
    "remove_space_and_dash = lambda word: word.strip().strip('-')\n",
    "to_lower_case = lambda word: word.lower()\n",
    "dept_name_to_code = lambda dept_name: department_codes[dept_name]\n",
    "\n",
    "# mapping\n",
    "offices['dept_code'] = offices['department'].map(remove_space_and_dash).map(to_lower_case).map(dept_name_to_code)\n",
    "offices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame and Higher Order Functions: .map( ) and .applymap( ) amd .apply( ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these three do something very simmilar, but in simplest terms:\n",
    "\n",
    "- **MAP()** works with column items, one at a time** \n",
    "- **APPLYMAP()** works with while DataFrame\n",
    "- **APPLY()** works lime map() but has access to the whole row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs']\n",
    "})\n",
    "\n",
    "to_upper_case = lambda word: word.upper()\n",
    "\n",
    "# map is used on a column\n",
    "foods['caps_name'] = foods['name'].map(to_upper_case)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs']\n",
    "})\n",
    "\n",
    "# applymap is used on a while dataframe\n",
    "new_foods = foods.applymap(to_upper_case)\n",
    "new_foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20]\n",
    "})\n",
    "\n",
    "\n",
    "string_from_row = lambda column: f\"{column['name']} from {column['supplier']} suits {column['diet']} diet\"\n",
    "\n",
    "# apply is used to create a new column, but has access to all columns \n",
    "foods['label'] = foods.apply(string_from_row, axis='columns')\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More of data cleaning and preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate a new column from rows with ```.assign( )```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Returns a new object with all original columns in addition to new ones. \n",
    "# Existing columns that are re-assigned will be overwritten.\"\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20]\n",
    "})\n",
    "\n",
    "foods = foods.assign(student_price = foods['price']*0.9, available = True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a change, **assign() does not change the original dataframe**. That's because if you specified 'inplace=True' it would just add a column called 'inplace' and put values True in every row of that column. It's just a peculiar price we need to pay for the power of assign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a column with ```.drop( )```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20]\n",
    "})\n",
    "\n",
    "foods.drop('supplier',axis='columns',inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace some data with ```.replace( )```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: **NaN** stands for \"Not a Number\" and is sort of like **None**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in ALL COLUMNS\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "# replace value 0 with NaN \n",
    "foods.replace(0, np.nan, inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in SELECTED COLUMNS\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "# replace value 0 with NaN - IN ALL COLUMNS\n",
    "foods['sold_since_year'].replace(0, np.nan, inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace many items with one replacement\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "foods.replace(['Vegetarian','Vegan'],['Not-Meat'],inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace many items with many replacements\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "foods.replace(['Vegetarian','Vegan', 'Meat'],['VEGE', 'VEGA', 'MEAT'],inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple statistics for all data and grouped by a value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe provide a full set of all statistical methods. If you need something specific, always look in the documentation https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "})\n",
    "\n",
    "# mean of all prices\n",
    "print( foods['price'].mean() )\n",
    "\n",
    "# mean of all prices, grouped by diet\n",
    "print( foods['price'].groupby(foods['diet']).mean() )\n",
    "print( foods['price'].groupby(foods['diet']).max() )\n",
    "print( foods['price'].groupby(foods['diet']).median() )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index - the most important part of your data (should be unique, but does not have to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not specify the index in your data, python will just use continuous numbers starting from 0 (like 0,1,2,3,4,...). Have a look at the dataframes you created before. Index is that number to the left. It's sort of like a row name in Excel.\n",
    "\n",
    "```.set_index(a_column_name)``` will set a column with name a_column_name to be the index\n",
    "\n",
    "```drop=True``` will make the old column disappear, otherwise, it will get duplicated (you'd have two identical columns: the original one, and the new index column)\n",
    "\n",
    "You could also have many columns act as  indexes, but we will not go into that. If you wanted to do that, just pass a List of column names to set_index rather than one column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0],\n",
    "    'sold_since_year': [2018, 2015, 0, 2012, 0, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can rename rows, columns, or both. Just specify a dict where key is the OLD VALUE, and value is the NEW VALUE.\n",
    "\n",
    "```{old_value: new_value, old_value_2: new_value_2}```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "foods.rename(index = {'Bagel':'Round Bun', 'Tap Water':'Water'}, columns={'supplier':'from'},inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also use string functions like str.upper\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "foods.rename(index = str.upper, columns=str.title ,inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also use your own lambda functions for mapping old value to new value\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', 'Vegetarian', 'Vegan', 'Meat', 'Vegetarian', 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', 'Water Tap'],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, 3.20, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "foods.rename(index = (lambda name: name[0:3]), columns=(lambda name: f\"The {name}\") ,inplace=True)\n",
    "foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import some data from a csv file. Panda simplified and streamlined importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we did not specify index_col, index would be 0,1,2,3,... but this data already has a gooid index \n",
    "data = pd.read_csv(\"edinburgh_airbnb_listings.csv\", index_col='id') \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories - Grouping results by a range of values. Use ```pd.data.cut( data, bins, labels )``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we want to categorise our data into particular groups by value. Given a set of values, we want to decide in which range they belong.\n",
    "\n",
    "Imagine a bunch of student exam scores (70,54,40,66) that we want to translate into grades (A,B,C,D,F).\n",
    "\n",
    "We will need a key of where one grade ends and another starts. One way to call them are bins (like buckets/containers) and our task is put each score in one of these bins.\n",
    "\n",
    "- F is (0, 40]\n",
    "- D is (40, 50]\n",
    "- C is (50, 60]\n",
    "- B is (60, 70]\n",
    "- A is (70, 100]\n",
    "\n",
    "Note: \n",
    "\n",
    "- '(' means the value is included in the bin\n",
    "- '[' means the value is excluded\n",
    "\n",
    "In panda you could describe it as ```[(0, 40] < (40, 50] < (50, 60] < (60, 70] < (70, 100]]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "student_scores = [40,54,60,66,70]\n",
    "bins = [0,40,50,60,70,100]\n",
    "labels = [\"F\",\"D\",\"C\",\"B\",\"A\"]\n",
    "\n",
    "# note: labels are optional, but very useful\n",
    "\n",
    "# cut will categorise\n",
    "categories = pd.cut(student_scores, bins, labels=[\"F\",\"D\",\"C\",\"B\",\"A\"], right=False)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want the rightmost elements to be included in the smaller category (eg. for score 40 to be an 'F')\n",
    "# use right=True argument, or just no right argument (True is a default)\n",
    "categories = pd.cut(student_scores, bins, labels=[\"F\",\"D\",\"C\",\"B\",\"A\"], right=True)\n",
    "print(categories)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use ```pd.cut(student_scores, bins, labels=[\"F\",\"D\",\"C\",\"B\",\"A\"])``` the resulting object contains information about \n",
    "\n",
    "- which category each of your data oints belongs to\n",
    "- what are the categories and their boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_scores = [40,54,60,66,70]\n",
    "bins = [0,40,50,60,70,100]\n",
    "labels = [\"F\",\"D\",\"C\",\"B\",\"A\"]\n",
    "categories = pd.cut(student_scores, bins, labels=labels)\n",
    "\n",
    "print(categories)\n",
    "print()\n",
    "print( categories.tolist() )\n",
    "print(categories.codes) # in older versions this was called .labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.value_counts(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.value_counts(categories).cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND FINALLY: Add a new column with bin values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame( {'student_scores': [40,54,60,66,70]} )\n",
    "bins = [0,40,50,60,70,100]\n",
    "labels = [\"F\",\"D\",\"C\",\"B\",\"A\"]\n",
    "\n",
    "data['grade'] = pd.cut(data['student_scores'], bins=bins, labels=labels)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up missing data (with NaN values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', None, 'Vegan', 'Meat', None, 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', None],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, None, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "print(\"Shape:\")\n",
    "print(foods.shape)\n",
    "print(\"Missing values:\")\n",
    "print(foods.isnull().sum())\n",
    "print(\"All values:\")\n",
    "print(foods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', None, 'Vegan', 'Meat', None, 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', None],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, None, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "# remove all rows with any missing values \n",
    "foods.dropna(inplace=True)\n",
    "\n",
    "print(\"Shape:\")\n",
    "print(foods.shape)\n",
    "print(\"Missing values:\")\n",
    "print(foods.isnull().sum())\n",
    "print(\"All values:\")\n",
    "print(foods)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = pd.DataFrame({\n",
    "    'name': ['Bagel', 'Milk Chocolate', 'Carrot', 'Ham Sandwich', 'Egg Cake', 'Tap Water'],\n",
    "    'diet':['Vegan', None, 'Vegan', 'Meat', None, 'Vegan'],\n",
    "    'supplier':['Bros', 'Luca', 'Whitmore', 'Union', 'Lovecrumbs', None],\n",
    "    'price':[4.30, 2.10, 0.7, 5.70, None, 0]\n",
    "}).set_index('name', drop=True)\n",
    "\n",
    "# Cleanup the Diet column:\n",
    "\n",
    "print(\"missing values in Diet:\", foods.diet.isna().sum())\n",
    "print(\"present values in Diet:\\n\", foods.diet.value_counts(sort=True))\n",
    "\n",
    "foods.diet.fillna('Unknown',inplace=True)\n",
    "print()\n",
    "\n",
    "print(\"missing values in Diet:\", foods.diet.isna().sum())\n",
    "print(\"present values in Diet:\\n\", foods.diet.value_counts(sort=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and keep cleaning up columns until there are no NaNs in all columns\n",
    "print(foods.isnull().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.target.value_counts()/train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train.education, train.target, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Panda Tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/edinburgh_airbnb_listings.csv\", index_col='id') \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take top x rows from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/edinburgh_airbnb_listings.csv\", index_col='id') \n",
    "\n",
    "# top 5 items\n",
    "data.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101',periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickly create some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some fake data quickly: combine np.arange( ) with .reshape()\n",
    "\n",
    "data = pd.DataFrame(np.arange(12).reshape((3, 4)),index=['Ohio', 'Colorado', 'New York'],columns=['one', 'two', 'three', 'four'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot tables - these qre are quite powerful, but we'll not talk about them much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'group': ['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],\n",
    "                 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "\n",
    "data.pivot_table(values='ounces',index='group',aggfunc=np.mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⭐️⭐️⭐️💥 What you learned in this session: Three stars and a wish \n",
    "**In yoru own words** write in your Learn diary:\n",
    "\n",
    "- 3 things you yould like to remember from this badge\n",
    "- 1 thing you wish to understand better in the future or a question you'd like to ask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⛏ Minitask 1: Explore two of the datasets\n",
    "\n",
    "- ask simple questions: what are the column names, how many records are there, etc\n",
    "- can you print just first 10 items, in just one of the columns? \n",
    "- what else did you learn about numpy and pandas that you could use on these datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local file\n",
    "data = pd.read_csv(\"data/edinburgh_airbnb_listings.csv\") \n",
    "print(data.columns) # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# online file\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"https://data.urbansharing.com/edinburghcyclehire.com/trips/v1/2020/10.csv\") \n",
    "print(data.columns) # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
